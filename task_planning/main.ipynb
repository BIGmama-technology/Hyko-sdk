{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample model db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.openai.requests import input_description, output_description\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output of this AI model would be a text caption that describes the content of the input image. The caption may describe objects, people, locations, or activities in the image. The model may also predict emotions, colors, and other attributes that are relevant to the image content. The caption may be a sentence or a short paragraph and should accurately reflect the most salient features of the image. The ultimate goal of this model is to provide a descriptive and informative context for the input image such that it can be easily understood and interpreted by humans.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_description(\"a model that takes in an image and outputs a caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(path_or_buf=\"data/huggingface_models.jsonl\", lines=True)\n",
    "model_db = data[[\"id\",\"task\",\"description\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db[\"input_desc\"] = model_db.description.apply(input_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db[\"output_desc\"] = model_db.description.apply(output_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "model_db.to_json(\"data/model_db.json\", orient=\"records\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.openai.requests import zero_shot_task_planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_task_plan = zero_shot_task_planning(\"a model that takes in an image and outputs a audio pronouncing caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = eval(zero_task_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_id': 'task1',\n",
       "  'task': 'image-captioning',\n",
       "  'task_description': 'Generate a textual caption from an image.',\n",
       "  'dep': [],\n",
       "  'inputs': [{'id': 'input1',\n",
       "    'input_type': 'image',\n",
       "    'input_description': 'Input image to the model.'}],\n",
       "  'outputs': [{'id': 'output1',\n",
       "    'output_type': 'text',\n",
       "    'output_description': 'Textual caption generated from the provided image.'}]},\n",
       " {'task_id': 'task2',\n",
       "  'task': 'text-to-speech',\n",
       "  'task_description': 'Convert textual caption to an audio file',\n",
       "  'dep': ['task1'],\n",
       "  'inputs': [{'id': 'input2',\n",
       "    'input_type': 'text',\n",
       "    'input_description': 'Textual caption generated from the previous step.'}],\n",
       "  'outputs': [{'id': 'output2',\n",
       "    'output_type': 'audio',\n",
       "    'output_description': 'The audio file that pronounces the textual caption.'}]}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"\n",
    "we need to make it easy for our employees to add and edit regulations. \n",
    "Adding a new regulation requires mutiple checks across thousands of pages of already existing regulations. \n",
    "During these checks (which takes months) emplyees look for conflicting regulations made earlier, \n",
    "loop holes and blind spots.\n",
    "find the relevent regulations, paragraphs and articles to the request\n",
    "check if a conflict occurs\n",
    "explain the conflict occuring\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task_plan= zero_shot_task_planning(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_id': 't1',\n",
       "  'task': 'Convert regulations into searchable format',\n",
       "  'task_description': 'Transform the existing regulations into a searchable format (e.g. text, pdf, etc.) that can be easily queried by other tasks',\n",
       "  'dep': [],\n",
       "  'inputs': [{'id': 'i1',\n",
       "    'input_type': 'pdf',\n",
       "    'input_description': 'Existing regulations in PDF format'}],\n",
       "  'outputs': [{'id': 'o1',\n",
       "    'output_type': 'text',\n",
       "    'output_description': 'Regulations in searchable text format'}]},\n",
       " {'task_id': 't2',\n",
       "  'task': 'Retrieve relevant regulations',\n",
       "  'task_description': \"Find the relevant regulations, paragraphs, and articles based on the user's request\",\n",
       "  'dep': ['t1'],\n",
       "  'inputs': [{'id': 'i2',\n",
       "    'input_type': 'text',\n",
       "    'input_description': \"User's request text\"}],\n",
       "  'outputs': [{'id': 'o2',\n",
       "    'output_type': 'text',\n",
       "    'output_description': 'List of relevant regulations, paragraphs, and articles in text format'}]},\n",
       " {'task_id': 't3',\n",
       "  'task': 'Check for conflicts',\n",
       "  'task_description': \"Identify potential conflicts between the existing regulations and the user's request\",\n",
       "  'dep': ['t2'],\n",
       "  'inputs': [{'id': 'i3_1',\n",
       "    'input_type': 'text',\n",
       "    'input_description': \"User's request text\"},\n",
       "   {'id': 'i3_2',\n",
       "    'input_type': 'text',\n",
       "    'input_description': 'List of relevant regulations, paragraphs, and articles in text format from task 2'}],\n",
       "  'outputs': [{'id': 'o3_1',\n",
       "    'output_type': 'text',\n",
       "    'output_description': 'List of potential conflicts in text format'},\n",
       "   {'id': 'o3_2',\n",
       "    'output_type': 'text',\n",
       "    'output_description': 'Explanation of each conflict in text format'}]}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = eval(test_task_plan)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject:str, task:str, description:str, inputs:dict, outputs:dict\n",
    "def problem(**kwargs):\n",
    "    return str(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_1 = problem(subject=\"document embedding\", \n",
    "        task=\"text splitting\", \n",
    "        description=\"divide text into chunks\", \n",
    "        inputs=\"[document text : str]\", \n",
    "        outputs=\"[list of sentences : list[str]]\")\n",
    "\n",
    "problem_2 = problem(subject=\"document embedding\", \n",
    "        task=\"text splitting\", \n",
    "        description=\"divide text into chunks\", \n",
    "        inputs=\"[document text : str]\", \n",
    "        outputs=\"[list of sentences : list[str]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "\"\"\"\n",
    "{\"subject\" : document embedding\n",
    "task : text splitting\n",
    "description : divide text into chunks\n",
    "inputs : [document text : str]\n",
    "output : list of sentences : list[str]}\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "\"subject\" : document embedding\n",
    "task : pdf to text\n",
    "description : turn the pdf into text while ignoring images\n",
    "inputs : [input documentation pdf : pdf]\n",
    "output : document text : str\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "\"subject\" : document embedding\n",
    "task : sentence embedding\n",
    "description : embed each sentence\n",
    "inputs : [list of sentences : list[str]]\n",
    "output : list of list of embeddings and list of sentences : list[list[str], list[float]]] \n",
    "\"\"\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
